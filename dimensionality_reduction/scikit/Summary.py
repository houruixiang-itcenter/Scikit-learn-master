#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2019/5/28 下午2:42
# @Author  : Aries
# @Site    : 
# @File    : Summary.py
# @Software: PyCharm
'''
维度的诅咒
'''
'''
场景:训练集涉及几千甚至几百万个特征,导致训练模型的速度非常慢,也让我们更加难以找到好的解决方案,这个问题通常被称为维度的诅咒

降维:
1.大量减少特征的数量,来保证训练的速度
2.对于可视化是非常有用的,将维度降到两个或者三个,可以在图形上绘制出高维训练集,来洞察更多的信息

一般情况下,降维可以加速训练,但是会轻微降低系统的性能,同时他会让流水线更为复杂,维护难度上升

理想状态下,某些情况下降维可以去除某些不必要的噪声和细节,从而导致性能更好,但是一般不会

降维的方法: 投影和流形学习

降维的技术: PCA Kernal PCA 以及 LLE
'''



'''
维度的诅咒

我们看这样一项的数据:
-----------------
在二维正方形中:一个点离边界距离小于0.001的概率是约0.4%
在1000维的单位超立方体中,这个概率大于 99.999999%
-----------------
二维立方体:随机挑选两个点,两点直接平均距离是0.52;
三维空间:平均距离是0.66
100万维的超立方体中平均距离是408.25



这就说明,维度越高,实例之间的距离就越远
这会直接导致,训练集的维度越高,过度拟合的风险越高

最直接有效的方式为,增加训练集

其次才是降维


'''


'''
降维方式1:----投影  简单数据集投影到一个平面

流行学习2:  将高纬数据集投影到一个可以扭动和弯曲的平面,这样可以防止投影数据的重合
'''

